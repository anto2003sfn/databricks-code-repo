{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "460c6a8f-d00e-45f9-8dd9-336b98e7b44b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Write SQL statements to create below objects \n",
    " - A catalog named telecom_catalog_assign </br>\n",
    " - A schema landing_zone <br>\n",
    " - A volume landing_vol <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69375cb5-46b9-4f8c-b33d-eead32c2604d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create catalog if not exists telecom_catalog_assign;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3219d47e-922a-45a4-83b8-62f2185f83a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "create schema if not exists telecom_catalog_assign.landing_zone;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4dbdccd-9752-486c-a642-a09361853f16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create volume  if not exists telecom_catalog_assign.landing_zone.landing_vol;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26a5a845-1906-4a40-8e91-ad6a4f10aa12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Using dbutils.fs.mkdirs, create below folders<br>\n",
    "- /Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/ <br>\n",
    "- /Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/ <br>\n",
    "- /Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3caa0d72-eda1-4c0a-a559-144f0cf7a1da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/\")\n",
    "dbutils.fs.mkdirs(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/\")\n",
    "dbutils.fs.mkdirs(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\")\n",
    "dbutils.fs.mkdirs(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82fa2d3c-aac4-472a-8160-dd0a08cd720f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create the customer , usage and tower logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07521254-7295-4768-8371-d7d41226a168",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "customer_csv = ''' 101,Arun,31,Chennai,PREPAID 102,Meera,45,Bangalore,POSTPAID 103,Irfan,29,Hyderabad,PREPAID 104,Raj,52,Mumbai,POSTPAID 105,,27,Delhi,PREPAID 106,Sneha,abc,Pune,PREPAID '''\n",
    "\n",
    "usage_tsv = '''customer_id\\tvoice_mins\\tdata_mb\\tsms_count 101\\t320\\t1500\\t20 102\\t120\\t4000\\t5 103\\t540\\t600\\t52 104\\t45\\t200\\t2 105\\t0\\t0\\t0 '''\n",
    "\n",
    "tower_logs_region = '''event_id|customer_id|tower_id|signal_strength|timestamp \n",
    "5001|101|TWR01|-80|2025-01-10 10:21:54 \n",
    "5004|104|TWR05|-75|2025-01-10 11:01:12 '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c4eefa-78c0-4245-9d05-a5884aeea29e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dbutils.fs.put(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer.csv\", customer_csv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae691128-548a-46a9-86f2-9921a1b10a2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# usage_tsv \n",
    "dbutils.fs.put(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/usage.tsv\",usage_tsv,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0db8408-e685-4886-9fbc-a946f5a70398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa5a045c-210a-47fd-94b2-610284ea1b2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dbutils.fs.put(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region1.csv\",tower_logs_region,True)\n",
    "dbutils.fs.put(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region2.csv\",tower_logs_region,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "413068db-1bac-4c38-aaf0-03f7347abe98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Driver program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0faf8955-7259-4b01-ad46-de581211277c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.appName(\"usecase3\").getOrCreate();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1b6c417-1456-4ae9-b673-a995ac4fcfe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.head(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2d0084b-9f17-4298-a647-93a29c1470dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = \"customer_id string,name string,age integer,city string,plan string\"\n",
    "df = sparkSession.read.csv(path=\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer.csv\",sep=',',schema=schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7e09bd-eaf5-407b-9d5a-c7d6460dbb92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "459ea0e1-d2c4-47b2-9cd2-2826b0287d31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.notebook.run('/Workspace/Users/anto2003.sfn@gmail.com/Usecase_3_solution',60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc26aea6-f895-4a03-986f-bdea34f28f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40c53d7e-3072-4ce9-abdc-18f78784cc31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usage_tsv = '''customer_id\\tvoice_mins\\tdata_mb\\tsms_count 101\\t320\\t1500\\t20 102\\t120\\t4000\\t5 103\\t540\\t600\\t52 104\\t45\\t200\\t2 105\\t0\\t0\\t0 '''\n",
    "\n",
    "usage_tsv_split = usage_tsv.strip().split(\" \")\n",
    "# usage_tsv_split = [item.strip()\n",
    "\n",
    "hdr = usage_tsv_split[0].split(\"\\t\")\n",
    "print(type(hdr))\n",
    "\n",
    "data = []\n",
    "for item in usage_tsv_split[1:]:\n",
    "    data.append(tuple(item.strip().split(\"\\t\")));\n",
    "print(data);\n",
    "\n",
    "df = spark.createDataFrame(data,hdr)\n",
    "display(df)\n",
    "# tower_logs_region = ''' 101\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b840c04-4501-41e8-b525-699660dc2660",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tower_logs_region = '''event_id|customer_id|tower_id|signal_strength|timestamp \n",
    "5001|101|TWR01|-80|2025-01-10 10:21:54 \n",
    "5004|104|TWR05|-75|2025-01-10 11:01:12 '''\n",
    "\n",
    "for item in tower_logs_region.split('\\n')[1:]:\n",
    "    # print(item.split(' '))\n",
    "    for lst in item.strip().split(' ',2):\n",
    "        print(lst.split('|'))\n",
    "    # print(item.split(' ',2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adb9718c-771d-4dbb-946a-2f68b9995db8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hdr = tower_logs_region.split(\" \")[0].split('|')\n",
    "\n",
    "data = []\n",
    "for item in tower_logs_region.split(' ')[1:]:\n",
    "    if len(item.split('|')) >2:\n",
    "        data.append(tuple(item.split('|')))\n",
    "df = spark.createDataFrame(data,hdr)\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90d9057b-0f40-4f5e-aa13-26ecb8d08b23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 3. Directory Read Use Cases<br>\n",
    "\n",
    "A. Read all tower logs using: Path glob filter (example: *.csv) Multiple paths input Recursive lookup<bR>\n",
    "\n",
    "B. Demonstrate these 3 reads separately: Using pathGlobFilter Using list of paths in spark.read.csv([path1, path2]) Using .option(\"recursiveFileLookup\",\"true\")<br>\n",
    "\n",
    "C.  Compare the outputs and understand when each should be used<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ae246c7-3d7a-433d-818f-78d7c3433001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Read all tower logs using: Path glob filter (example: *.csv) Multiple paths input Recursive lookup\n",
    "\n",
    "df = spark.read.csv(path = \"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\",sep='|',header=True,pathGlobFilter=\"*.csv\",recursiveFileLookup=True)\n",
    "display(df)\n",
    "\n",
    "\n",
    "# Data cleanup needed as per Irfan's dataset\n",
    "\n",
    "# tower_logs_region = dbutils.fs.head(\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region1.csv\")\n",
    "# print(str)\n",
    "\n",
    "# hdr = tower_logs_region.split(\" \")[0].split('|')\n",
    "\n",
    "# data = []\n",
    "# for item in tower_logs_region.split(' ')[1:]:\n",
    "#     if len(item.split('|',2)) >2:\n",
    "#         data.append(tuple(item.split('|')))\n",
    "# df = spark.createDataFrame(data,hdr)\n",
    "# display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0404945-c772-49d5-ab98-7352e2ad67d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# A. Read all tower logs using: Path glob filter (example: *.csv) Multiple paths input Recursive lookup\n",
    "\n",
    "df = spark.read.csv(path = [\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region1.csv\",\"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region2.csv\",], sep='|', header=True, recursiveFileLookup=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8a9e1d7-789c-4b0b-b8f1-598fd359e728",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765734396748}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e4c5f1-3ac7-4d7e-8bbc-adfe8a2ccc9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = spark.read.csv(path = \"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region*.csv\", sep='|', header=True, recursiveFileLookup=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28bd7e88-1d8d-432e-90ed-4a5ff8d7a49c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "4. Schema Inference, Header, and Separator\n",
    "Try the Customer, Usage files with the option and options using read.csv and format function:\n",
    "header=false, inferSchema=false\n",
    "or\n",
    "header=true, inferSchema=true\n",
    "Write a note on What changed when we use header or inferSchema with true/false?\n",
    "How schema inference handled “abc” in age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44895691-9ec7-4026-ab5f-d447a749877b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df =spark.read.csv(path = \"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer.csv\" , header = False, inferSchema=False\n",
    ")\n",
    "\n",
    "df.show()\n",
    "\n",
    "# column names are defined with _c0, _c1, _c2, _c3, _c4, _c5, _c6, _c7\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ef1a05-815d-4424-8e25-e95097fb0db8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df =spark.read.csv(path = \"dbfs:///Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer.csv\" , header = True,sep=','\n",
    ")\n",
    "\n",
    "display(df)\n",
    "\n",
    "# column values are converted to column header\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f8665db-b68e-45ba-9cad-00d2a7ae7608",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. Column Renaming Usecases<br>\n",
    "Apply column names using string using toDF function for customer data<br>\n",
    "Apply column names and datatype using the schema function for usage data<br>\n",
    "Apply column names and datatype using the StructType with IntegerType, StringType, TimestampType and other classes for towers data<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5bee902-d2a1-4453-b04d-b89148c19751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "def getlist():\n",
    "    customer_csv = ''' 101,Arun,31,Chennai,PREPAID 102,Meera,45,Bangalore,POSTPAID 103,Irfan,29,Hyderabad,PREPAID 104,Raj,52,Mumbai,POSTPAID 105,,27,Delhi,PREPAID 106,Sneha,abc,Pune,PREPAID ''';\n",
    "    data = [];\n",
    "    customer_csv_split = customer_csv.strip().split(\" \");\n",
    "    for item in customer_csv_split:\n",
    "        data.append(tuple(item.split(\",\")));\n",
    "    return data;\n",
    "\n",
    "\n",
    "data = getlist();\n",
    "df = sparkSession.createDataFrame(data,schema=[\"customer_id\",\"name\",\"age\",\"city\",\"plan\"]);\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "551d5116-b466-4a0a-b0cd-75bebac95113",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usage_tsv = '''customer_id\\tvoice_mins\\tdata_mb\\tsms_count 101\\t320\\t1500\\t20 102\\t120\\t4000\\t5 103\\t540\\t600\\t52 104\\t45\\t200\\t2 105\\t0\\t0\\t0 '''\n",
    "\n",
    "usage_tsv_split = usage_tsv.strip().split(\" \")\n",
    "# usage_tsv_split = [item.strip()\n",
    "\n",
    "hdr = usage_tsv_split[0].split(\"\\t\")\n",
    "print(type(hdr))\n",
    "\n",
    "data = []\n",
    "for item in usage_tsv_split[1:]:\n",
    "    data.append(tuple(item.strip().split(\"\\t\")));\n",
    "print(data);\n",
    "\n",
    "df = spark.createDataFrame(data,hdr)\n",
    "display(df)\n",
    "# tower_logs_region = ''' 101\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ced9e4e4-f121-4f46-ac39-5a12047e80ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from io import StringIO\n",
    "import pandas as pd # Used for an intermediate step to handle the structured text easily\n",
    "\n",
    "# Initialize Spark Session (if not already running)\n",
    "# spark = SparkSession.builder.appName(\"DataConversion\").getOrCreate()\n",
    "\n",
    "# # --- 1. The Raw Data ---\n",
    "# data_string = \"\"\"event_id|customer_id|tower_id|signal_strength|timestamp\n",
    "# 5001|101|TWR01|-80|2025-01-10 10:21:54\n",
    "# 5004|104|TWR05|-75|2025-01-10 11:01:12\"\"\"\n",
    "\n",
    "\n",
    "data_string = '''event_id|customer_id|tower_id|signal_strength|timestamp\n",
    " 5001|101|TWR01|-80|2025-01-10 10:21:54 \n",
    " 5004|104|TWR05|-75|2025-01-10 11:01:12 '''\n",
    "\n",
    "# --- 2. Convert to Spark DataFrame ---\n",
    "\n",
    "# The most common and robust way when the data is a local string:\n",
    "\n",
    "# a) Read the string into a Pandas DataFrame first\n",
    "df_pd = pd.read_csv(StringIO(data_string), sep='|')\n",
    "\n",
    "# b) Convert the Pandas DataFrame to a Spark DataFrame\n",
    "df_spark = spark.createDataFrame(df_pd)\n",
    "\n",
    "# --- 3. Display the Result ---\n",
    "print(\"--- Spark DataFrame Schema ---\")\n",
    "df_spark.printSchema()\n",
    "\n",
    "print(\"\\n--- Spark DataFrame Content ---\")\n",
    "df_spark.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7763424960604032,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Usecase_3_problemstatement",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
