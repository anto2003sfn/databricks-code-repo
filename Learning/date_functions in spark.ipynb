{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b00524ec-798e-4b2b-8aa6-3849da0750ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "            .appName('SparkByExamples.com') \\\n",
    "            .getOrCreate()\n",
    "data=[[\"1\",\"2020-02-01\"],[\"2\",\"2019-03-01\"],[\"3\",\"2021-03-01\"]]\n",
    "df=spark.createDataFrame(data,[\"id\",\"input\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e0e4f18-1126-4090-bf0a-e495db01bc67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.select(\"*\",current_date().alias(\"dt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbeb7674-d0f1-4d5c-8bc6-d2616e00f7f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c59c27b1-0bd1-434d-a376-9bb00d444b18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\"*\",\n",
    "          date_format(col(\"input\"),'dd-MM-yyyy').alias(\"fdt\"), \\\n",
    "          to_date(\"input\",\"yyyy-MM-dd\").alias(\"todt\"),  \\\n",
    "          trunc(col(\"input\"),\"Month\").alias(\"Month_Trunc\"),  \\\n",
    "    trunc(col(\"input\"),\"Year\").alias(\"Month_Year\"),  \\\n",
    "    datediff(current_date(),col(\"input\")).alias(\"datediff\") , \\\n",
    "    months_between(current_date(),col(\"input\")).alias(\"months_between\") , \\\n",
    "       add_months(col(\"input\"),3).alias(\"add_months\"), \\\n",
    "    add_months(col(\"input\"),-3).alias(\"sub_months\"), \\\n",
    "    date_add(col(\"input\"),4).alias(\"date_add\"), \\\n",
    "    date_sub(col(\"input\"),4).alias(\"date_sub\") , \\\n",
    "     year(col(\"input\")).alias(\"year\"), \\\n",
    "     month(col(\"input\")).alias(\"month\"),  \\\n",
    "     next_day(col(\"input\"),\"Sunday\").alias(\"next_day\"),  \\\n",
    "     weekofyear(col(\"input\")).alias(\"weekofyear\") ,\\\n",
    "         dayofweek(col(\"input\")).alias(\"dayofweek\"), \\\n",
    "     dayofmonth(col(\"input\")).alias(\"dayofmonth\"), \\\n",
    "     dayofyear(col(\"input\")).alias(\"dayofyear\"), \n",
    "              ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1153333-436c-4357-b100-f9e7d7ae3375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data=[[\"1\",\"02-01-2020 11 01 19 06\"],[\"2\",\"03-01-2019 12 01 19 406\"],[\"3\",\"03-01-2021 12 01 19 406\"]]\n",
    "df2=spark.createDataFrame(data,[\"id\",\"input\"])\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d92d326-450e-43a0-9de0-d13817af90cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2.select(current_timestamp().alias(\"current_timestamp\")\n",
    "  ).show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a968097c-ae03-4f58-8f59-35f17787a99a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2.select(col(\"input\"), \n",
    "    to_timestamp(col(\"input\"), \"MM-dd-yyyy HH mm ss SSS\").alias(\"to_timestamp\") \n",
    "  ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74457f35-03ab-4c04-a03f-35f77d23e8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#hour, minute,second\n",
    "data=[[\"1\",\"2020-02-01 11:01:19.06\"],[\"2\",\"2019-03-01 12:01:19.406\"],[\"3\",\"2021-03-01 12:01:19.406\"]]\n",
    "df3=spark.createDataFrame(data,[\"id\",\"input\"])\n",
    "\n",
    "df3.select(col(\"input\"), \n",
    "    hour(col(\"input\")).alias(\"hour\"), \n",
    "    minute(col(\"input\")).alias(\"minute\"),\n",
    "    second(col(\"input\")).alias(\"second\") \n",
    "  ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05592de2-2a5d-4993-aed9-9d64b94c37fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions.aggregate import *\n",
    "\n",
    "df4 = df.select(\"input\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a59aae86-91e8-4255-9be3-80307ddacc9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df4.select(\"input\",trunc(\"input\",'year')).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "date_functions in spark",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
