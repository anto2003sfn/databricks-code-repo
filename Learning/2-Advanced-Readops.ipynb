{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f23a9042-0c4e-41d8-9c1c-427a0cbcb775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Options for handling quotes & Escape\n",
    "\n",
    "id,name,remarks\n",
    "1,'Ramesh, K.P','Good performer'\n",
    "2,'Manoj','Needs ~'special~' attention'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a368f3c7-3407-432a-b66c-7f714c57ff0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Comments, Multi line, leading and trailing whitespace handling, null and nan handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f5f54bc-e2ab-428c-8436-36f070a6dd5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Read modes in csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01e4a4d8-ece9-4f93-895a-104d57b61a43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### There are 3 typical read modes and the default read mode is permissive.\n",
    "##### 1. permissive — All fields are set to null and corrupted records are placed in a string column called _corrupt_record\n",
    "##### \t2. dropMalformed — Drops all rows containing corrupt records.\n",
    "##### 3. failFast — Fails when corrupt records are encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a56955f-761b-46d6-a7c0-7a706e2b0391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "335941dc-0879-472b-a888-d44f0dbd9684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####4. Max advanced features used...\n",
    "\\#This is a commented line and should be ignored\n",
    "\"ID\",\"Name\",\"Age\",\"Salary\",\"JoinDate\",\"LastLogin\",\"Notes\"\n",
    "1,\"John Doe\",28,45000.50,01-2025-25,2024-01-25 10:15:45,\"New employee\"\n",
    "2,\"Jane, Smith\",32,55000.00,2023-12-30,2024-01-25 14:05:10\n",
    "3,\"Ravi Kumar\",-1,67000.75,2023-11-05,2024-02-01 08:30:00,\"Null age\",\"addon cols\"\n",
    "4,\"李小龍\",45,88000.00,2022-05-18,2024-01-19 13:45:22,\"UTF-8 Chinese name\"\n",
    "5,\"Carlos \\\"The Boss\\\" Pérez\",38,72000.30,2023-02-11,2024-01-28 09:55:05,\"Contains quotes\"\n",
    "6,\"Manoj\",29,50000,2024-02-10,2024-02-10 17:25:55,\"Line\n",
    "break\n",
    "inside notes\"\n",
    "7,\"Anita\",41,na,2023-10-08,2024-02-02 11:11:11,\"Salary is NaN\"\n",
    "8,\"Robert\",34,47000.20,2023-06-22,2024-01-27 18:40:40,  \"Leading and trailing spaces\"   \n",
    "9,\"\",30,39000.00,2023-09-19,2024-01-26 16:20:20,\"Empty name field\"\n",
    "10,\"#NotAComment\",37,51000.10,02-2025-25,2024-02-03 12:55:30,\"Starts with # but not a comment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d40ce5e-0345-410d-a83b-7629b1e2bbbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csvData =\"\"\"\"ID\",\"Name\",\"Age\",\"Salary\",\"JoinDate\",\"LastLogin\",\"Notes\"\n",
    "1,\"John Doe\",28,45000.50,01-2025-25,2024-01-25 10:15:45,\"New employee\"\n",
    "2,\"Jane, Smith\",32,55000.00,2023-12-30,2024-01-25 14:05:10\n",
    "3,\"Ravi Kumar\",-1,67000.75,2023-11-05,2024-02-01 08:30:00,\"Null age\",\"addon cols\"\n",
    "4,\"李小龍\",45,88000.00,2022-05-18,2024-01-19 13:45:22,\"UTF-8 Chinese name\"\n",
    "5,\"Carlos \\\"The Boss\\\" Pérez\",38,72000.30,2023-02-11,2024-01-28 09:55:05,\"Contains quotes\"\n",
    "6,\"Manoj\",29,50000,2024-02-10,2024-02-10 17:25:55,\"Line\n",
    "break\n",
    "inside notes\"\n",
    "7,\"Anita\",41,na,2023-10-08,2024-02-02 11:11:11,\"Salary is NaN\"\n",
    "8,\"Robert\",34,47000.20,2023-06-22,2024-01-27 18:40:40,  \"Leading and trailing spaces\"   \n",
    "9,\"\",30,39000.00,2023-09-19,2024-01-26 16:20:20,\"Empty name field\"\n",
    "10,\"#NotAComment\",37,51000.10,02-2025-25,2024-02-03 12:55:30,\"Starts with # but not a comment\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc83d713-1a9b-42a6-8763-1a47d51d11e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(csvData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c39514-3ed8-4158-bd4d-e66456cf0456",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create database if not exists wd36schema;\n",
    "create volume if not exists wd36schema.ingestion_volume;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bda57021-2126-4911-9a96-6ac39af589bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "dbutils.fs.mkdirs(\"/Volumes/workspace/wd36schema/ingestion_volume/target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542bb533-996a-48aa-9014-fcdc97c398d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.put(\"/Volumes/workspace/wd36schema/ingestion_volume/target/csvout\",csvData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d57d48e7-a9b0-44ae-8127-1ea20b3a2f7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####5. Reading data from other formats (Try the below usecases after completing the 3-Basic-WriteOps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2924108e-b6f6-4c3d-84f4-82d8e32cfd30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####1. Reading csv data with 3 different mode based on the correupted record\n",
    "\n",
    "1 Fail the load if the data has corrupted<br>\n",
    "2 drop the records if it is corrupted<br>\n",
    "3 allow the corrupted record with null values eventhough corrupted <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e33ca0f-feeb-4213-a2fe-98ff53aed2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mode = FailFast\n",
    "spark.read.csv(\"/Volumes/workspace/wd36schema/ingestion_volume/target/csvout\",header=True,sep=\",\",inferSchema=True,mode=\"FailFast\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f37e8db2-16a1-4eda-a1c9-12bac9f75b86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#DropMalformed\n",
    "\n",
    "csv_df = spark.read.csv(\"/Volumes/workspace/wd36schema/ingestion_volume/target/csvout\",header=True,sep=\",\",inferSchema=True,mode=\"DropMalformed\");\n",
    "display(csv_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "367bc187-cd69-450f-814c-3ccf8a1297f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Permissive\n",
    "df = spark.read.csv(\"/Volumes/workspace/wd36schema/ingestion_volume/target/csvout\",header=True,sep=\",\",inferSchema=True,mode=\"Permissive\");\n",
    "df.printSchema()\n",
    "lst =df.printSchema\n",
    "print(lst)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aac93e0c-6739-419e-8fa9-196a4441576f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Handling the corrupted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "238b2602-b0f6-4bca-9ff7-b69c5dbcfdcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "# ID: string, Name: string, Age: int, Salary: string, JoinDate: string, LastLogin: timestamp, Notes: string\n",
    "# 1. Define schema + the special error column\n",
    "schema = StructType([\n",
    "     StructField(\"id\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"Salary\", StringType(), True),\n",
    "    StructField(\"JoinDate\", StringType(), True),\n",
    "    StructField(\"LastLogin\", StringType(), True),\n",
    "    StructField(\"Notes\", StringType(), True),\n",
    "    StructField(\"_corrupt_record\", StringType(), True) # Special column\n",
    "])\n",
    "\n",
    "# 2. Read with the columnNameOfCorruptRecord option\n",
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"mode\", \"PERMISSIVE\")\n",
    "      .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\")\n",
    "      .schema(schema)\n",
    "      .load(\"dbfs:///Volumes/workspace/wd36schema/ingestion_volume/target/csvout\"))\n",
    "\n",
    "# 3. View only the broken records\n",
    "# display(df)\n",
    "display(df.filter(df._corrupt_record.isNull()))\n",
    "\n",
    "df.write.mode(\"overwrite\").json(\"/Volumes/workspace/wd36schema/ingestion_volume/target/jsonout\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cedba05f-92a8-4a75-a982-4ca7a803527b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").xml(\"/Volumes/workspace/wd36schema/ingestion_volume/target/xmlout\",rowTag=\"cust\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "664e9b51-371e-4250-8151-365a30f33b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####2. Reading json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a253bdb3-3899-47a1-ad67-1dae1238652e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_json = spark.read.json(\"dbfs:///Volumes/workspace/wd36schema/ingestion_volume/target/jsonout/\")\n",
    "df_json.printSchema();\n",
    "\n",
    "display(df_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1039ff97-9c7f-4eec-bd3c-196fa67a3e5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####3. Reading xml data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cb0deb6-3d01-4d53-8b25-ef5435991b73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.xml(\"/Volumes/workspace/wd36schema/ingestion_volume/target/xmlout\",rowTag=\"cust\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b484bce8-2d2f-4b4d-a33d-09af56cf7e3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").orc(\"/Volumes/workspace/wd36schema/ingestion_volume/target/orcout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1845cf-8a20-4ccf-800d-8cd145cf62dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####4. Reading serialized data (orc/parquet/delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdfad5fa-79c3-40aa-88d6-fdf3ae434a5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####5. Reading delta/hive table data"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4627515290441186,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2-Advanced-Readops",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
